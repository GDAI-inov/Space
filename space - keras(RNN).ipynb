{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Np</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Vp</th>\n",
       "      <th>B_gsm_x</th>\n",
       "      <th>B_gsm_y</th>\n",
       "      <th>B_gsm_z</th>\n",
       "      <th>Bmag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01 00:00</th>\n",
       "      <td>1.225355</td>\n",
       "      <td>32956.035503</td>\n",
       "      <td>443.036509</td>\n",
       "      <td>5.142349</td>\n",
       "      <td>1.988692</td>\n",
       "      <td>-12.914000</td>\n",
       "      <td>14.143320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 03:00</th>\n",
       "      <td>1.613686</td>\n",
       "      <td>55713.597041</td>\n",
       "      <td>431.723491</td>\n",
       "      <td>3.574822</td>\n",
       "      <td>-2.570586</td>\n",
       "      <td>-9.271053</td>\n",
       "      <td>11.855373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 06:00</th>\n",
       "      <td>1.191851</td>\n",
       "      <td>80571.958333</td>\n",
       "      <td>432.390536</td>\n",
       "      <td>4.361542</td>\n",
       "      <td>-5.262113</td>\n",
       "      <td>-7.125196</td>\n",
       "      <td>10.517149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 09:00</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>149231.295858</td>\n",
       "      <td>428.213609</td>\n",
       "      <td>3.533574</td>\n",
       "      <td>-6.503805</td>\n",
       "      <td>4.220485</td>\n",
       "      <td>9.589148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 12:00</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>77718.396450</td>\n",
       "      <td>413.764024</td>\n",
       "      <td>6.511308</td>\n",
       "      <td>-6.137467</td>\n",
       "      <td>-0.664426</td>\n",
       "      <td>9.313183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Np             Tp          Vp   B_gsm_x   B_gsm_y  \\\n",
       "date                                                                   \n",
       "01-01 00:00  1.225355   32956.035503  443.036509  5.142349  1.988692   \n",
       "01-01 03:00  1.613686   55713.597041  431.723491  3.574822 -2.570586   \n",
       "01-01 06:00  1.191851   80571.958333  432.390536  4.361542 -5.262113   \n",
       "01-01 09:00  1.100000  149231.295858  428.213609  3.533574 -6.503805   \n",
       "01-01 12:00  1.100000   77718.396450  413.764024  6.511308 -6.137467   \n",
       "\n",
       "               B_gsm_z       Bmag  \n",
       "date                               \n",
       "01-01 00:00 -12.914000  14.143320  \n",
       "01-01 03:00  -9.271053  11.855373  \n",
       "01-01 06:00  -7.125196  10.517149  \n",
       "01-01 09:00   4.220485   9.589148  \n",
       "01-01 12:00  -0.664426   9.313183  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ace = pd.DataFrame()\n",
    "for name in os.listdir('proc_data/total')[:-1]:\n",
    "    ins_data = pd.read_csv(f'proc_data/total/{name}', index_col=0, parse_dates=['date'])\n",
    "    ace = pd.concat([ace, ins_data], axis=0)\n",
    "\n",
    "problem = pd.read_csv(\"proc_data/problem.csv\", index_col=0, parse_dates=['date'])\n",
    "problem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc0 /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(tf.__version__, (tf.test.gpu_device_name() if tf.test.is_gpu_available() else None))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ace = ace.reset_index().drop(np.where(np.round(ace.iloc[:, -2].values) == -10000)[0]).set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40903, 7, 1) (40903, 10) (2920, 7, 1)\n",
      "(26177, 7, 1) (6545, 7, 1) (8181, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "ace_x, ace_y = ace.iloc[:, :-1].values, \\\n",
    "    keras.utils.to_categorical(ace.target.values, 10)\n",
    "problem_x = tf.constant(problem.values[:, :, np.newaxis])\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(ace_x, ace_y, test_size=0.2, random_state=1, shuffle=False)\n",
    "x_train, x_val, y_train, y_val = \\\n",
    "    train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "ace_x, ace_y, x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "    tf.constant(ace_x[:, :, np.newaxis]), tf.constant(ace_y), \\\n",
    "    tf.constant(x_train[:, :, np.newaxis]), tf.constant(y_train), \\\n",
    "    tf.constant(x_val[:, :, np.newaxis]), tf.constant(y_val), \\\n",
    "    tf.constant(x_test[:, :, np.newaxis]), tf.constant(y_test)\n",
    "\n",
    "print(ace_x.shape, ace_y.shape, problem_x.shape)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40903, 7, 1) (40903, 10) (2920, 7, 1)\n",
      "(26177, 7, 1) (6545, 7, 1) (8181, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "ace_x, ace_y = np.concatenate((np.array(scaler.fit_transform(ace.iloc[:, :3])), np.absolute(ace.iloc[:, 3:-1].values)), 1), \\\n",
    "    keras.utils.to_categorical(ace.target.values, 10)\n",
    "problem_x = tf.constant(np.concatenate((np.array(scaler.fit_transform(problem.iloc[:, :3])), np.absolute(problem.iloc[:, 3:].values)), 1)[:, :, np.newaxis])\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(ace_x, ace_y, test_size=0.2, random_state=1, shuffle=False)\n",
    "x_train, x_val, y_train, y_val = \\\n",
    "    train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "ace_x, ace_y, x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "    tf.constant(ace_x[:, :, np.newaxis]), tf.constant(ace_y), \\\n",
    "    tf.constant(x_train[:, :, np.newaxis]), tf.constant(y_train), \\\n",
    "    tf.constant(x_val[:, :, np.newaxis]), tf.constant(y_val), \\\n",
    "    tf.constant(x_test[:, :, np.newaxis]), tf.constant(y_test)\n",
    "\n",
    "print(ace_x.shape, ace_y.shape, problem_x.shape)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_10 (SimpleRNN)    (None, 64)                4224      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                490       \n",
      "=================================================================\n",
      "Total params: 7,834\n",
      "Trainable params: 7,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.SimpleRNN(64, input_shape=(7, 1)))\n",
    "model.add(layers.Dense(48, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='linear'))\n",
    "model.compile(optimizer=optim, loss=loss_fn, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26177 samples, validate on 6545 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000204C50BD620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000204C50BD620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "26177/26177 [==============================] - 17s 639us/sample - loss: 0.0760 - acc: 0.3448 - val_loss: 0.0720 - val_acc: 0.4069\n",
      "Epoch 2/50\n",
      "26177/26177 [==============================] - 16s 604us/sample - loss: 0.0708 - acc: 0.3933 - val_loss: 0.0705 - val_acc: 0.3976\n",
      "Epoch 3/50\n",
      "26177/26177 [==============================] - 16s 607us/sample - loss: 0.0698 - acc: 0.4047 - val_loss: 0.0721 - val_acc: 0.3969\n",
      "Epoch 4/50\n",
      "26177/26177 [==============================] - 17s 639us/sample - loss: 0.0695 - acc: 0.4128 - val_loss: 0.0720 - val_acc: 0.4018\n",
      "Epoch 5/50\n",
      "26177/26177 [==============================] - 16s 616us/sample - loss: 0.0694 - acc: 0.4144 - val_loss: 0.0690 - val_acc: 0.4188\n",
      "Epoch 6/50\n",
      "26177/26177 [==============================] - 17s 651us/sample - loss: 0.0692 - acc: 0.4136 - val_loss: 0.0688 - val_acc: 0.4174\n",
      "Epoch 7/50\n",
      "26177/26177 [==============================] - 17s 631us/sample - loss: 0.0691 - acc: 0.4194 - val_loss: 0.0700 - val_acc: 0.4151\n",
      "Epoch 8/50\n",
      "26177/26177 [==============================] - 16s 598us/sample - loss: 0.0690 - acc: 0.4197 - val_loss: 0.0685 - val_acc: 0.4261\n",
      "Epoch 9/50\n",
      "26177/26177 [==============================] - 15s 590us/sample - loss: 0.0687 - acc: 0.4219 - val_loss: 0.0685 - val_acc: 0.4356\n",
      "Epoch 10/50\n",
      "26177/26177 [==============================] - 16s 596us/sample - loss: 0.0688 - acc: 0.4219 - val_loss: 0.0684 - val_acc: 0.4306\n",
      "Epoch 11/50\n",
      "26177/26177 [==============================] - 15s 586us/sample - loss: 0.0687 - acc: 0.4225 - val_loss: 0.0675 - val_acc: 0.4342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'epochs': 50,\n",
       " 'steps': 1637,\n",
       " 'samples': 26177,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=16, epochs=50, callbacks=[early_stop], validation_data=(x_val, y_val))\n",
    "hist.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.06955213378124461 - acc: 0.38442733883857727\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(problem_x)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m%d_%H%M')\n",
    "pred = pd.DataFrame(pred.reshape(365, 8), index=range(1, 366), columns=[f\"kp_{_}h\" for _ in range(0, 24, 3)])\n",
    "pred.to_csv(f\"models/rnn{timestamp}(loss{round(float(loss), 3)}_acc{round(float(acc), 2)}).csv\")\n",
    "\n",
    "print(f\"loss: {loss} - acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40903 samples\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000204C4D55E18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000204C4D55E18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "40903/40903 - 22s - loss: 0.0755 - acc: 0.3490\n",
      "Epoch 2/25\n",
      "40903/40903 - 21s - loss: 0.0716 - acc: 0.3854\n",
      "Epoch 3/25\n",
      "40903/40903 - 22s - loss: 0.0709 - acc: 0.3893\n",
      "Epoch 4/25\n",
      "40903/40903 - 22s - loss: 0.0706 - acc: 0.3951\n",
      "Epoch 5/25\n",
      "40903/40903 - 22s - loss: 0.0704 - acc: 0.3944\n",
      "Epoch 6/25\n",
      "40903/40903 - 23s - loss: 0.0701 - acc: 0.3973\n",
      "Epoch 7/25\n",
      "40903/40903 - 22s - loss: 0.0701 - acc: 0.3982\n",
      "Epoch 8/25\n",
      "40903/40903 - 22s - loss: 0.0700 - acc: 0.4004\n",
      "Epoch 9/25\n",
      "40903/40903 - 22s - loss: 0.0698 - acc: 0.4002\n",
      "Epoch 10/25\n",
      "40903/40903 - 22s - loss: 0.0700 - acc: 0.3993\n",
      "Epoch 11/25\n",
      "40903/40903 - 22s - loss: 0.0698 - acc: 0.4007\n",
      "Epoch 12/25\n",
      "40903/40903 - 22s - loss: 0.0697 - acc: 0.4026\n",
      "Epoch 13/25\n",
      "40903/40903 - 22s - loss: 0.0697 - acc: 0.4017\n",
      "Epoch 14/25\n",
      "40903/40903 - 22s - loss: 0.0696 - acc: 0.4044\n",
      "Epoch 15/25\n",
      "40903/40903 - 22s - loss: 0.0697 - acc: 0.4039\n",
      "Epoch 16/25\n",
      "40903/40903 - 22s - loss: 0.0696 - acc: 0.4059\n",
      "Epoch 17/25\n",
      "40903/40903 - 22s - loss: 0.0696 - acc: 0.4041\n",
      "Epoch 18/25\n",
      "40903/40903 - 22s - loss: 0.0695 - acc: 0.4012\n",
      "Epoch 19/25\n",
      "40903/40903 - 22s - loss: 0.0695 - acc: 0.4062\n",
      "Epoch 20/25\n",
      "40903/40903 - 22s - loss: 0.0694 - acc: 0.4055\n",
      "Epoch 21/25\n",
      "40903/40903 - 21s - loss: 0.0695 - acc: 0.4077\n",
      "Epoch 22/25\n",
      "40903/40903 - 22s - loss: 0.0694 - acc: 0.4054\n",
      "Epoch 23/25\n",
      "40903/40903 - 22s - loss: 0.0694 - acc: 0.4033\n",
      "Epoch 24/25\n",
      "40903/40903 - 22s - loss: 0.0695 - acc: 0.4058\n",
      "Epoch 25/25\n",
      "40903/40903 - 22s - loss: 0.0693 - acc: 0.4092\n"
     ]
    }
   ],
   "source": [
    "model.fit(ace_x, ace_y, batch_size=16, epochs=25, verbose=2)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "timestamp = datetime.now().strftime('%Y-%m%d_%H%M')\n",
    "pred = model.predict_classes(problem_x)\n",
    "pred = pd.DataFrame(pred.reshape(365, 8), index=range(1, 366), columns=[f\"kp_{_}h\" for _ in range(0, 24, 3)])\n",
    "pred.to_csv(f\"models/ace_rnn{timestamp}(loss{round(float(loss), 3)}_acc{round(float(acc), 2)}).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
