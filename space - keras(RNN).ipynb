{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Np</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Vp</th>\n",
       "      <th>B_gsm_x</th>\n",
       "      <th>B_gsm_y</th>\n",
       "      <th>B_gsm_z</th>\n",
       "      <th>Bmag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01 00:00</th>\n",
       "      <td>-2484.213799</td>\n",
       "      <td>31225.352663</td>\n",
       "      <td>72.326686</td>\n",
       "      <td>5.142349</td>\n",
       "      <td>1.988692</td>\n",
       "      <td>-12.914000</td>\n",
       "      <td>14.143320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 03:00</th>\n",
       "      <td>-2779.787349</td>\n",
       "      <td>53214.458580</td>\n",
       "      <td>61.408107</td>\n",
       "      <td>3.574822</td>\n",
       "      <td>-2.570586</td>\n",
       "      <td>-9.271053</td>\n",
       "      <td>11.855373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 06:00</th>\n",
       "      <td>-3511.071315</td>\n",
       "      <td>42789.192262</td>\n",
       "      <td>-1991.056964</td>\n",
       "      <td>4.361542</td>\n",
       "      <td>-5.262113</td>\n",
       "      <td>-7.125196</td>\n",
       "      <td>10.517149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 09:00</th>\n",
       "      <td>-9999.900000</td>\n",
       "      <td>38898.049704</td>\n",
       "      <td>-6612.537456</td>\n",
       "      <td>3.533574</td>\n",
       "      <td>-6.503805</td>\n",
       "      <td>4.220485</td>\n",
       "      <td>9.589148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 12:00</th>\n",
       "      <td>-9999.900000</td>\n",
       "      <td>65806.125444</td>\n",
       "      <td>-510.487337</td>\n",
       "      <td>6.511308</td>\n",
       "      <td>-6.137467</td>\n",
       "      <td>-0.664426</td>\n",
       "      <td>9.313183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Np            Tp           Vp   B_gsm_x   B_gsm_y  \\\n",
       "date                                                                      \n",
       "01-01 00:00 -2484.213799  31225.352663    72.326686  5.142349  1.988692   \n",
       "01-01 03:00 -2779.787349  53214.458580    61.408107  3.574822 -2.570586   \n",
       "01-01 06:00 -3511.071315  42789.192262 -1991.056964  4.361542 -5.262113   \n",
       "01-01 09:00 -9999.900000  38898.049704 -6612.537456  3.533574 -6.503805   \n",
       "01-01 12:00 -9999.900000  65806.125444  -510.487337  6.511308 -6.137467   \n",
       "\n",
       "               B_gsm_z       Bmag  \n",
       "date                               \n",
       "01-01 00:00 -12.914000  14.143320  \n",
       "01-01 03:00  -9.271053  11.855373  \n",
       "01-01 06:00  -7.125196  10.517149  \n",
       "01-01 09:00   4.220485   9.589148  \n",
       "01-01 12:00  -0.664426   9.313183  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ace = pd.DataFrame()\n",
    "for name in os.listdir('proc_data/total')[:-1]:\n",
    "    ins_data = pd.read_csv(f'proc_data/total/{name}', index_col=0, parse_dates=['date'])\n",
    "    ace = pd.concat([ace, ins_data], axis=0)\n",
    "\n",
    "problem = pd.read_csv(\"proc_data/problem.csv\", index_col=0, parse_dates=['date'])\n",
    "problem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc0 /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(tf.__version__, (tf.test.gpu_device_name() if tf.test.is_gpu_available() else None))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40912, 7, 1) (40912, 10) (2920, 7, 1)\n",
      "(26183, 7, 1) (6546, 7, 1) (8183, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "ace_x, ace_y = ace.iloc[:, :-1].values, \\\n",
    "    keras.utils.to_categorical(ace.target.values, 10)\n",
    "problem_x = tf.constant(problem.values[:, :, np.newaxis])\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(ace_x, ace_y, test_size=0.2, random_state=1, shuffle=False)\n",
    "x_train, x_val, y_train, y_val = \\\n",
    "    train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "ace_x, ace_y, x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "    tf.constant(ace_x[:, :, np.newaxis]), tf.constant(ace_y), \\\n",
    "    tf.constant(x_train[:, :, np.newaxis]), tf.constant(y_train), \\\n",
    "    tf.constant(x_val[:, :, np.newaxis]), tf.constant(y_val), \\\n",
    "    tf.constant(x_test[:, :, np.newaxis]), tf.constant(y_test)\n",
    "\n",
    "print(ace_x.shape, ace_y.shape, problem_x.shape)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40912, 7, 1) (40912, 10) (2920, 7, 1)\n",
      "(26183, 7, 1) (6546, 7, 1) (8183, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# ace_x, ace_y = scaler.fit_transform(ace.iloc[:, :-1].values), \\\n",
    "#     keras.utils.to_categorical(ace.target.values, 10)\n",
    "# problem_x = tf.constant(scaler.fit_transform(problem.values)[:, :, np.newaxis])\n",
    "\n",
    "# x_train, x_test, y_train, y_test = \\\n",
    "#     train_test_split(ace_x, ace_y, test_size=0.2, random_state=1, shuffle=False)\n",
    "# x_train, x_val, y_train, y_val = \\\n",
    "#     train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "# ace_x, ace_y, x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "#     tf.constant(ace_x[:, :, np.newaxis]), tf.constant(ace_y), \\\n",
    "#     tf.constant(x_train[:, :, np.newaxis]), tf.constant(y_train), \\\n",
    "#     tf.constant(x_val[:, :, np.newaxis]), tf.constant(y_val), \\\n",
    "#     tf.constant(x_test[:, :, np.newaxis]), tf.constant(y_test)\n",
    "\n",
    "# print(ace_x.shape, ace_y.shape, problem_x.shape)\n",
    "# print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_5 (SimpleRNN)     (None, 64)                4224      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 4,874\n",
      "Trainable params: 4,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.SimpleRNN(64, input_shape=(7, 1), dropout=0.1))\n",
    "model.add(layers.Dense(10, activation='linear'))\n",
    "model.compile(optimizer=optim, loss=loss_fn, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26183 samples, validate on 6546 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001E87DD3BD08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001E87DD3BD08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "26183/26183 [==============================] - 16s 627us/sample - loss: 0.0820 - acc: 0.3339 - val_loss: 0.0759 - val_acc: 0.3361\n",
      "Epoch 2/50\n",
      "26183/26183 [==============================] - 15s 591us/sample - loss: 0.0743 - acc: 0.3531 - val_loss: 0.0726 - val_acc: 0.3740\n",
      "Epoch 3/50\n",
      "26183/26183 [==============================] - 15s 592us/sample - loss: 0.0736 - acc: 0.3645 - val_loss: 0.0729 - val_acc: 0.3701\n",
      "Epoch 4/50\n",
      "26183/26183 [==============================] - 16s 599us/sample - loss: 0.0731 - acc: 0.3684 - val_loss: 0.0728 - val_acc: 0.3894\n",
      "Epoch 5/50\n",
      "26183/26183 [==============================] - 16s 595us/sample - loss: 0.0729 - acc: 0.3660 - val_loss: 0.0714 - val_acc: 0.3978\n",
      "Epoch 6/50\n",
      "26183/26183 [==============================] - 16s 597us/sample - loss: 0.0728 - acc: 0.3677 - val_loss: 0.0725 - val_acc: 0.3584\n",
      "Epoch 7/50\n",
      "26183/26183 [==============================] - 16s 606us/sample - loss: 0.0725 - acc: 0.3738 - val_loss: 0.0726 - val_acc: 0.3721\n",
      "Epoch 8/50\n",
      "26183/26183 [==============================] - 16s 600us/sample - loss: 0.0725 - acc: 0.3728 - val_loss: 0.0736 - val_acc: 0.3709\n",
      "Epoch 9/50\n",
      "26183/26183 [==============================] - 16s 594us/sample - loss: 0.0723 - acc: 0.3760 - val_loss: 0.0715 - val_acc: 0.3888\n",
      "Epoch 10/50\n",
      "26183/26183 [==============================] - 15s 587us/sample - loss: 0.0722 - acc: 0.3752 - val_loss: 0.0743 - val_acc: 0.3582\n",
      "Epoch 11/50\n",
      "26183/26183 [==============================] - 16s 601us/sample - loss: 0.0724 - acc: 0.3780 - val_loss: 0.0723 - val_acc: 0.3746\n",
      "Epoch 12/50\n",
      "26183/26183 [==============================] - 15s 592us/sample - loss: 0.0721 - acc: 0.3804 - val_loss: 0.0712 - val_acc: 0.3902\n",
      "Epoch 13/50\n",
      "26183/26183 [==============================] - 16s 597us/sample - loss: 0.0720 - acc: 0.3740 - val_loss: 0.0707 - val_acc: 0.4028\n",
      "Epoch 14/50\n",
      "26183/26183 [==============================] - 16s 600us/sample - loss: 0.0719 - acc: 0.3818 - val_loss: 0.0709 - val_acc: 0.4074\n",
      "Epoch 15/50\n",
      "26183/26183 [==============================] - 16s 602us/sample - loss: 0.0717 - acc: 0.3823 - val_loss: 0.0714 - val_acc: 0.3847\n",
      "Epoch 16/50\n",
      "26183/26183 [==============================] - 16s 600us/sample - loss: 0.0717 - acc: 0.3844 - val_loss: 0.0714 - val_acc: 0.3827\n",
      "Epoch 17/50\n",
      "26183/26183 [==============================] - 15s 589us/sample - loss: 0.0717 - acc: 0.3818 - val_loss: 0.0705 - val_acc: 0.3984\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'epochs': 50,\n",
       " 'steps': 1637,\n",
       " 'samples': 26183,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=16, epochs=50, callbacks=[early_stop], validation_data=(x_val, y_val))\n",
    "hist.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0694235591394284 - acc: 0.40596356987953186\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(problem_x)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m%d_%H%M')\n",
    "pred = pd.DataFrame(pred.reshape(365, 8), index=range(1, 366), columns=[f\"kp_{_}h\" for _ in range(0, 24, 3)])\n",
    "pred.to_csv(f\"models/rnn{timestamp}(loss{round(float(loss), 3)}_acc{round(float(acc), 2)}).csv\")\n",
    "\n",
    "print(f\"loss: {loss} - acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40912 samples\n",
      "Epoch 1/50\n",
      "40912/40912 - 11s - loss: 0.0701 - acc: 0.4012\n",
      "Epoch 2/50\n",
      "40912/40912 - 11s - loss: 0.0701 - acc: 0.3968\n",
      "Epoch 3/50\n",
      "40912/40912 - 11s - loss: 0.0703 - acc: 0.3943\n",
      "Epoch 4/50\n",
      "40912/40912 - 11s - loss: 0.0700 - acc: 0.4002\n",
      "Epoch 5/50\n",
      "40912/40912 - 11s - loss: 0.0699 - acc: 0.4025\n",
      "Epoch 6/50\n",
      "40912/40912 - 11s - loss: 0.0701 - acc: 0.3974\n",
      "Epoch 7/50\n",
      "40912/40912 - 11s - loss: 0.0701 - acc: 0.3952\n",
      "Epoch 8/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4028\n",
      "Epoch 9/50\n",
      "40912/40912 - 11s - loss: 0.0701 - acc: 0.3971\n",
      "Epoch 10/50\n",
      "40912/40912 - 11s - loss: 0.0700 - acc: 0.3997\n",
      "Epoch 11/50\n",
      "40912/40912 - 11s - loss: 0.0699 - acc: 0.4017\n",
      "Epoch 12/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4024\n",
      "Epoch 13/50\n",
      "40912/40912 - 11s - loss: 0.0699 - acc: 0.3997\n",
      "Epoch 14/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4027\n",
      "Epoch 15/50\n",
      "40912/40912 - 11s - loss: 0.0700 - acc: 0.3989\n",
      "Epoch 16/50\n",
      "40912/40912 - 11s - loss: 0.0699 - acc: 0.4002\n",
      "Epoch 17/50\n",
      "40912/40912 - 11s - loss: 0.0697 - acc: 0.4070\n",
      "Epoch 18/50\n",
      "40912/40912 - 11s - loss: 0.0697 - acc: 0.4018\n",
      "Epoch 19/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4043\n",
      "Epoch 20/50\n",
      "40912/40912 - 11s - loss: 0.0700 - acc: 0.3991\n",
      "Epoch 21/50\n",
      "40912/40912 - 11s - loss: 0.0699 - acc: 0.4012\n",
      "Epoch 22/50\n",
      "40912/40912 - 11s - loss: 0.0697 - acc: 0.4022\n",
      "Epoch 23/50\n",
      "40912/40912 - 11s - loss: 0.0697 - acc: 0.4008\n",
      "Epoch 24/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4019\n",
      "Epoch 25/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4047\n",
      "Epoch 26/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4013\n",
      "Epoch 27/50\n",
      "40912/40912 - 11s - loss: 0.0697 - acc: 0.4038\n",
      "Epoch 28/50\n",
      "40912/40912 - 11s - loss: 0.0697 - acc: 0.4031\n",
      "Epoch 29/50\n",
      "40912/40912 - 11s - loss: 0.0697 - acc: 0.4062\n",
      "Epoch 30/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4062\n",
      "Epoch 31/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4039\n",
      "Epoch 32/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4012\n",
      "Epoch 33/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4047\n",
      "Epoch 34/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4041\n",
      "Epoch 35/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4042\n",
      "Epoch 36/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4027\n",
      "Epoch 37/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4040\n",
      "Epoch 38/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4022\n",
      "Epoch 39/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4048\n",
      "Epoch 40/50\n",
      "40912/40912 - 11s - loss: 0.0695 - acc: 0.4061\n",
      "Epoch 41/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4047\n",
      "Epoch 42/50\n",
      "40912/40912 - 11s - loss: 0.0698 - acc: 0.4034\n",
      "Epoch 43/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4048\n",
      "Epoch 44/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4051\n",
      "Epoch 45/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4052\n",
      "Epoch 46/50\n",
      "40912/40912 - 11s - loss: 0.0695 - acc: 0.4080\n",
      "Epoch 47/50\n",
      "40912/40912 - 11s - loss: 0.0696 - acc: 0.4044\n",
      "Epoch 48/50\n",
      "40912/40912 - 11s - loss: 0.0695 - acc: 0.4054\n",
      "Epoch 49/50\n",
      "40912/40912 - 11s - loss: 0.0695 - acc: 0.4063\n",
      "Epoch 50/50\n",
      "40912/40912 - 11s - loss: 0.0697 - acc: 0.4040\n"
     ]
    }
   ],
   "source": [
    "model.fit(ace_x, ace_y, batch_size=32, epochs=50, verbose=2)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "timestamp = datetime.now().strftime('%Y-%m%d_%H%M')\n",
    "pred = model.predict_classes(problem_x)\n",
    "pred = pd.DataFrame(pred.reshape(365, 8), index=range(1, 366), columns=[f\"kp_{_}h\" for _ in range(0, 24, 3)])\n",
    "pred.to_csv(f\"models/ace_rnn{timestamp}(loss{round(float(loss), 3)}_acc{round(float(acc), 2)}).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
