{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Np</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Vp</th>\n",
       "      <th>B_gsm_x</th>\n",
       "      <th>B_gsm_y</th>\n",
       "      <th>B_gsm_z</th>\n",
       "      <th>Bmag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01 00:00</th>\n",
       "      <td>1.225355</td>\n",
       "      <td>32956.035503</td>\n",
       "      <td>443.036509</td>\n",
       "      <td>5.142349</td>\n",
       "      <td>1.988692</td>\n",
       "      <td>-12.914000</td>\n",
       "      <td>14.143320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 03:00</th>\n",
       "      <td>1.613686</td>\n",
       "      <td>55713.597041</td>\n",
       "      <td>431.723491</td>\n",
       "      <td>3.574822</td>\n",
       "      <td>-2.570586</td>\n",
       "      <td>-9.271053</td>\n",
       "      <td>11.855373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 06:00</th>\n",
       "      <td>1.191851</td>\n",
       "      <td>80571.958333</td>\n",
       "      <td>432.390536</td>\n",
       "      <td>4.361542</td>\n",
       "      <td>-5.262113</td>\n",
       "      <td>-7.125196</td>\n",
       "      <td>10.517149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 09:00</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>149231.295858</td>\n",
       "      <td>428.213609</td>\n",
       "      <td>3.533574</td>\n",
       "      <td>-6.503805</td>\n",
       "      <td>4.220485</td>\n",
       "      <td>9.589148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 12:00</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>77718.396450</td>\n",
       "      <td>413.764024</td>\n",
       "      <td>6.511308</td>\n",
       "      <td>-6.137467</td>\n",
       "      <td>-0.664426</td>\n",
       "      <td>9.313183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Np             Tp          Vp   B_gsm_x   B_gsm_y  \\\n",
       "date                                                                   \n",
       "01-01 00:00  1.225355   32956.035503  443.036509  5.142349  1.988692   \n",
       "01-01 03:00  1.613686   55713.597041  431.723491  3.574822 -2.570586   \n",
       "01-01 06:00  1.191851   80571.958333  432.390536  4.361542 -5.262113   \n",
       "01-01 09:00  1.100000  149231.295858  428.213609  3.533574 -6.503805   \n",
       "01-01 12:00  1.100000   77718.396450  413.764024  6.511308 -6.137467   \n",
       "\n",
       "               B_gsm_z       Bmag  \n",
       "date                               \n",
       "01-01 00:00 -12.914000  14.143320  \n",
       "01-01 03:00  -9.271053  11.855373  \n",
       "01-01 06:00  -7.125196  10.517149  \n",
       "01-01 09:00   4.220485   9.589148  \n",
       "01-01 12:00  -0.664426   9.313183  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ace = pd.DataFrame()\n",
    "for name in os.listdir('proc_data/total')[:-1]:\n",
    "    ins_data = pd.read_csv(f'proc_data/total/{name}', index_col=0, parse_dates=['date'])\n",
    "    ace = pd.concat([ace, ins_data], axis=0)\n",
    "\n",
    "problem = pd.read_csv(\"proc_data/problem.csv\", index_col=0, parse_dates=['date'])\n",
    "problem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc0 /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(tf.__version__, (tf.test.gpu_device_name() if tf.test.is_gpu_available() else None))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Np</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Vp</th>\n",
       "      <th>B_gsm_x</th>\n",
       "      <th>B_gsm_y</th>\n",
       "      <th>B_gsm_z</th>\n",
       "      <th>Bmag</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40912.000000</td>\n",
       "      <td>40912.000000</td>\n",
       "      <td>40912.000000</td>\n",
       "      <td>40912.000000</td>\n",
       "      <td>40912.000000</td>\n",
       "      <td>40912.000000</td>\n",
       "      <td>40912.000000</td>\n",
       "      <td>40912.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.178479</td>\n",
       "      <td>93579.836013</td>\n",
       "      <td>414.624933</td>\n",
       "      <td>0.097037</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>5.902348</td>\n",
       "      <td>2.004229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.775639</td>\n",
       "      <td>64456.974444</td>\n",
       "      <td>110.238196</td>\n",
       "      <td>3.361752</td>\n",
       "      <td>3.638149</td>\n",
       "      <td>2.715169</td>\n",
       "      <td>3.220644</td>\n",
       "      <td>1.380313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.338422</td>\n",
       "      <td>6232.843937</td>\n",
       "      <td>66.548106</td>\n",
       "      <td>-38.509988</td>\n",
       "      <td>-38.029685</td>\n",
       "      <td>-45.768521</td>\n",
       "      <td>0.633787</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.259211</td>\n",
       "      <td>52401.416494</td>\n",
       "      <td>343.497503</td>\n",
       "      <td>-2.367654</td>\n",
       "      <td>-2.259315</td>\n",
       "      <td>-1.183234</td>\n",
       "      <td>3.894521</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.952537</td>\n",
       "      <td>74337.671242</td>\n",
       "      <td>398.913996</td>\n",
       "      <td>0.221396</td>\n",
       "      <td>-0.055723</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>5.166678</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.733943</td>\n",
       "      <td>115685.124727</td>\n",
       "      <td>475.995315</td>\n",
       "      <td>2.534049</td>\n",
       "      <td>2.216305</td>\n",
       "      <td>1.237614</td>\n",
       "      <td>7.021472</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.267275</td>\n",
       "      <td>824408.526771</td>\n",
       "      <td>1136.113815</td>\n",
       "      <td>24.709669</td>\n",
       "      <td>37.354456</td>\n",
       "      <td>32.136882</td>\n",
       "      <td>55.763702</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Np             Tp            Vp       B_gsm_x       B_gsm_y  \\\n",
       "count  40912.000000   40912.000000  40912.000000  40912.000000  40912.000000   \n",
       "mean       5.178479   93579.836013    414.624933      0.097037      0.001105   \n",
       "std        3.775639   64456.974444    110.238196      3.361752      3.638149   \n",
       "min        0.338422    6232.843937     66.548106    -38.509988    -38.029685   \n",
       "25%        3.259211   52401.416494    343.497503     -2.367654     -2.259315   \n",
       "50%        3.952537   74337.671242    398.913996      0.221396     -0.055723   \n",
       "75%        5.733943  115685.124727    475.995315      2.534049      2.216305   \n",
       "max       83.267275  824408.526771   1136.113815     24.709669     37.354456   \n",
       "\n",
       "            B_gsm_z          Bmag        target  \n",
       "count  40912.000000  40912.000000  40912.000000  \n",
       "mean       0.020896      5.902348      2.004229  \n",
       "std        2.715169      3.220644      1.380313  \n",
       "min      -45.768521      0.633787      0.000000  \n",
       "25%       -1.183234      3.894521      1.000000  \n",
       "50%        0.038888      5.166678      2.000000  \n",
       "75%        1.237614      7.021472      3.000000  \n",
       "max       32.136882     55.763702      9.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ace[ace <= -9999] = np.nan\n",
    "\n",
    "# ace = ace.reset_index().drop(np.where(ace.values >= -9999)[0]).set_index('date')\n",
    "ace.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40903, 7, 1) (40903, 10) (2920, 7, 1)\n",
      "(26177, 7, 1) (6545, 7, 1) (8181, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "ace_x, ace_y = ace.iloc[:, :-1].values, \\\n",
    "    keras.utils.to_categorical(ace.target.values, 10)\n",
    "problem_x = tf.constant(problem.values[:, :, np.newaxis])\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(ace_x, ace_y, test_size=0.2, random_state=1, shuffle=False)\n",
    "x_train, x_val, y_train, y_val = \\\n",
    "    train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "ace_x, ace_y, x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "    tf.constant(ace_x[:, :, np.newaxis]), tf.constant(ace_y), \\\n",
    "    tf.constant(x_train[:, :, np.newaxis]), tf.constant(y_train), \\\n",
    "    tf.constant(x_val[:, :, np.newaxis]), tf.constant(y_val), \\\n",
    "    tf.constant(x_test[:, :, np.newaxis]), tf.constant(y_test)\n",
    "\n",
    "print(ace_x.shape, ace_y.shape, problem_x.shape)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40912, 7, 1) (40912, 10) (2920, 7, 1)\n",
      "(26183, 7, 1) (6546, 7, 1) (8183, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "ace_x, ace_y = np.concatenate((np.array(scaler.fit_transform(ace.iloc[:, :3])), np.absolute(ace.iloc[:, 3:-1].values)), 1), \\\n",
    "    keras.utils.to_categorical(ace.target.values, 10)\n",
    "problem_x = tf.constant(np.concatenate((np.array(scaler.fit_transform(problem.iloc[:, :3])), np.absolute(problem.iloc[:, 3:].values)), 1)[:, :, np.newaxis])\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(ace_x, ace_y, test_size=0.2, random_state=1, shuffle=False)\n",
    "x_train, x_val, y_train, y_val = \\\n",
    "    train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "ace_x, ace_y, x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "    tf.constant(ace_x[:, :, np.newaxis]), tf.constant(ace_y), \\\n",
    "    tf.constant(x_train[:, :, np.newaxis]), tf.constant(y_train), \\\n",
    "    tf.constant(x_val[:, :, np.newaxis]), tf.constant(y_val), \\\n",
    "    tf.constant(x_test[:, :, np.newaxis]), tf.constant(y_test)\n",
    "\n",
    "print(ace_x.shape, ace_y.shape, problem_x.shape)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 64)                4224      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                490       \n",
      "=================================================================\n",
      "Total params: 7,834\n",
      "Trainable params: 7,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.SimpleRNN(64, input_shape=(7, 1)))\n",
    "model.add(layers.Dense(48, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='linear'))\n",
    "model.compile(optimizer=optim, loss=loss_fn, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26183 samples, validate on 6546 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001F529B7DBF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001F529B7DBF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "26183/26183 [==============================] - 17s 642us/sample - loss: 0.0781 - acc: 0.3307 - val_loss: 0.0735 - val_acc: 0.3543\n",
      "Epoch 2/50\n",
      "26183/26183 [==============================] - 15s 582us/sample - loss: 0.0731 - acc: 0.3665 - val_loss: 0.0717 - val_acc: 0.3816\n",
      "Epoch 3/50\n",
      "26183/26183 [==============================] - 15s 587us/sample - loss: 0.0718 - acc: 0.3773 - val_loss: 0.0720 - val_acc: 0.3715\n",
      "Epoch 4/50\n",
      " 3696/26183 [===>..........................] - ETA: 12s - loss: 0.0718 - acc: 0.3715"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d509b6a36489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    732\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    413\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1820\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=16, epochs=50, callbacks=[early_stop], validation_data=(x_val, y_val))\n",
    "hist.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.06955213378124461 - acc: 0.38442733883857727\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(problem_x)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m%d_%H%M')\n",
    "pred = pd.DataFrame(pred.reshape(365, 8), index=range(1, 366), columns=[f\"kp_{_}h\" for _ in range(0, 24, 3)])\n",
    "pred.to_csv(f\"models/rnn{timestamp}(loss{round(float(loss), 3)}_acc{round(float(acc), 2)}).csv\")\n",
    "\n",
    "print(f\"loss: {loss} - acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40903 samples\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000204C4D55E18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000204C4D55E18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "40903/40903 - 22s - loss: 0.0755 - acc: 0.3490\n",
      "Epoch 2/25\n",
      "40903/40903 - 21s - loss: 0.0716 - acc: 0.3854\n",
      "Epoch 3/25\n",
      "40903/40903 - 22s - loss: 0.0709 - acc: 0.3893\n",
      "Epoch 4/25\n",
      "40903/40903 - 22s - loss: 0.0706 - acc: 0.3951\n",
      "Epoch 5/25\n",
      "40903/40903 - 22s - loss: 0.0704 - acc: 0.3944\n",
      "Epoch 6/25\n",
      "40903/40903 - 23s - loss: 0.0701 - acc: 0.3973\n",
      "Epoch 7/25\n",
      "40903/40903 - 22s - loss: 0.0701 - acc: 0.3982\n",
      "Epoch 8/25\n",
      "40903/40903 - 22s - loss: 0.0700 - acc: 0.4004\n",
      "Epoch 9/25\n",
      "40903/40903 - 22s - loss: 0.0698 - acc: 0.4002\n",
      "Epoch 10/25\n",
      "40903/40903 - 22s - loss: 0.0700 - acc: 0.3993\n",
      "Epoch 11/25\n",
      "40903/40903 - 22s - loss: 0.0698 - acc: 0.4007\n",
      "Epoch 12/25\n",
      "40903/40903 - 22s - loss: 0.0697 - acc: 0.4026\n",
      "Epoch 13/25\n",
      "40903/40903 - 22s - loss: 0.0697 - acc: 0.4017\n",
      "Epoch 14/25\n",
      "40903/40903 - 22s - loss: 0.0696 - acc: 0.4044\n",
      "Epoch 15/25\n",
      "40903/40903 - 22s - loss: 0.0697 - acc: 0.4039\n",
      "Epoch 16/25\n",
      "40903/40903 - 22s - loss: 0.0696 - acc: 0.4059\n",
      "Epoch 17/25\n",
      "40903/40903 - 22s - loss: 0.0696 - acc: 0.4041\n",
      "Epoch 18/25\n",
      "40903/40903 - 22s - loss: 0.0695 - acc: 0.4012\n",
      "Epoch 19/25\n",
      "40903/40903 - 22s - loss: 0.0695 - acc: 0.4062\n",
      "Epoch 20/25\n",
      "40903/40903 - 22s - loss: 0.0694 - acc: 0.4055\n",
      "Epoch 21/25\n",
      "40903/40903 - 21s - loss: 0.0695 - acc: 0.4077\n",
      "Epoch 22/25\n",
      "40903/40903 - 22s - loss: 0.0694 - acc: 0.4054\n",
      "Epoch 23/25\n",
      "40903/40903 - 22s - loss: 0.0694 - acc: 0.4033\n",
      "Epoch 24/25\n",
      "40903/40903 - 22s - loss: 0.0695 - acc: 0.4058\n",
      "Epoch 25/25\n",
      "40903/40903 - 22s - loss: 0.0693 - acc: 0.4092\n"
     ]
    }
   ],
   "source": [
    "model.fit(ace_x, ace_y, batch_size=16, epochs=25, verbose=2)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "timestamp = datetime.now().strftime('%Y-%m%d_%H%M')\n",
    "pred = model.predict_classes(problem_x)\n",
    "pred = pd.DataFrame(pred.reshape(365, 8), index=range(1, 366), columns=[f\"kp_{_}h\" for _ in range(0, 24, 3)])\n",
    "pred.to_csv(f\"models/ace_rnn{timestamp}(loss{round(float(loss), 3)}_acc{round(float(acc), 2)}).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
