{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Np</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Vp</th>\n",
       "      <th>B_gsm_x</th>\n",
       "      <th>B_gsm_y</th>\n",
       "      <th>B_gsm_z</th>\n",
       "      <th>Bmag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01 00:00</th>\n",
       "      <td>1.225355</td>\n",
       "      <td>32956.035503</td>\n",
       "      <td>443.036509</td>\n",
       "      <td>5.142349</td>\n",
       "      <td>1.988692</td>\n",
       "      <td>-12.914000</td>\n",
       "      <td>14.143320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 03:00</th>\n",
       "      <td>1.613686</td>\n",
       "      <td>55713.597041</td>\n",
       "      <td>431.723491</td>\n",
       "      <td>3.574822</td>\n",
       "      <td>-2.570586</td>\n",
       "      <td>-9.271053</td>\n",
       "      <td>11.855373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 06:00</th>\n",
       "      <td>1.191851</td>\n",
       "      <td>80571.958333</td>\n",
       "      <td>432.390536</td>\n",
       "      <td>4.361542</td>\n",
       "      <td>-5.262113</td>\n",
       "      <td>-7.125196</td>\n",
       "      <td>10.517149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 09:00</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>149231.295858</td>\n",
       "      <td>428.213609</td>\n",
       "      <td>3.533574</td>\n",
       "      <td>-6.503805</td>\n",
       "      <td>4.220485</td>\n",
       "      <td>9.589148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01 12:00</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>77718.396450</td>\n",
       "      <td>413.764024</td>\n",
       "      <td>6.511308</td>\n",
       "      <td>-6.137467</td>\n",
       "      <td>-0.664426</td>\n",
       "      <td>9.313183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Np             Tp          Vp   B_gsm_x   B_gsm_y  \\\n",
       "date                                                                   \n",
       "01-01 00:00  1.225355   32956.035503  443.036509  5.142349  1.988692   \n",
       "01-01 03:00  1.613686   55713.597041  431.723491  3.574822 -2.570586   \n",
       "01-01 06:00  1.191851   80571.958333  432.390536  4.361542 -5.262113   \n",
       "01-01 09:00  1.100000  149231.295858  428.213609  3.533574 -6.503805   \n",
       "01-01 12:00  1.100000   77718.396450  413.764024  6.511308 -6.137467   \n",
       "\n",
       "               B_gsm_z       Bmag  \n",
       "date                               \n",
       "01-01 00:00 -12.914000  14.143320  \n",
       "01-01 03:00  -9.271053  11.855373  \n",
       "01-01 06:00  -7.125196  10.517149  \n",
       "01-01 09:00   4.220485   9.589148  \n",
       "01-01 12:00  -0.664426   9.313183  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ace = pd.DataFrame()\n",
    "for name in os.listdir('proc_data/total')[:-1]:\n",
    "    ins_data = pd.read_csv(f'proc_data/total/{name}', index_col=0, parse_dates=['date'])\n",
    "    ace = pd.concat([ace, ins_data], axis=0)\n",
    "\n",
    "problem = pd.read_csv(\"proc_data/problem.csv\", index_col=0, parse_dates=['date'])\n",
    "problem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc0 /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(tf.__version__, (tf.test.gpu_device_name() if tf.test.is_gpu_available() else None))\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40912, 7, 1) (40912, 10) (2920, 7, 1)\n",
      "(26183, 7, 1) (6546, 7, 1) (8183, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "ace_x, ace_y = ace.iloc[:, :-1].values, \\\n",
    "    keras.utils.to_categorical(ace.target.values, 10)\n",
    "problem_x = tf.constant(problem.values[:, :, np.newaxis])\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(ace_x, ace_y, test_size=0.2, random_state=1, shuffle=False)\n",
    "x_train, x_val, y_train, y_val = \\\n",
    "    train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "ace_x, ace_y, x_train, y_train, x_val, y_val, x_test, y_test = \\\n",
    "    tf.constant(ace_x[:, :, np.newaxis]), tf.constant(ace_y), \\\n",
    "    tf.constant(x_train[:, :, np.newaxis]), tf.constant(y_train), \\\n",
    "    tf.constant(x_val[:, :, np.newaxis]), tf.constant(y_val), \\\n",
    "    tf.constant(x_test[:, :, np.newaxis]), tf.constant(y_test)\n",
    "\n",
    "print(ace_x.shape, ace_y.shape, problem_x.shape)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 24)                792       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                250       \n",
      "=================================================================\n",
      "Total params: 18,850\n",
      "Trainable params: 18,722\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.GRU(64, input_shape=(7, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(48, activation='tanh'))\n",
    "model.add(layers.Dense(32, activation='tanh'))\n",
    "model.add(layers.Dense(24, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='linear'))\n",
    "model.compile(optimizer=optim, loss=loss_fn, metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26183 samples, validate on 6546 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016DE4DC4EA0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016DE4DC4EA0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "26183/26183 [==============================] - 15s 576us/sample - loss: 0.0794 - acc: 0.3458 - val_loss: 0.1083 - val_acc: 0.2377\n",
      "Epoch 2/100\n",
      "26183/26183 [==============================] - 13s 515us/sample - loss: 0.0739 - acc: 0.3737 - val_loss: 0.0833 - val_acc: 0.3237\n",
      "Epoch 3/100\n",
      "26183/26183 [==============================] - 13s 502us/sample - loss: 0.0721 - acc: 0.3878 - val_loss: 0.0837 - val_acc: 0.3032\n",
      "Epoch 4/100\n",
      "26183/26183 [==============================] - 13s 512us/sample - loss: 0.0710 - acc: 0.3975 - val_loss: 0.0810 - val_acc: 0.3425\n",
      "Epoch 5/100\n",
      "26183/26183 [==============================] - 13s 502us/sample - loss: 0.0703 - acc: 0.4080 - val_loss: 0.0806 - val_acc: 0.2904\n",
      "Epoch 6/100\n",
      "26183/26183 [==============================] - 13s 508us/sample - loss: 0.0698 - acc: 0.4136 - val_loss: 0.0887 - val_acc: 0.2314\n",
      "Epoch 7/100\n",
      "26183/26183 [==============================] - 13s 509us/sample - loss: 0.0696 - acc: 0.4109 - val_loss: 0.0981 - val_acc: 0.1688\n",
      "Epoch 8/100\n",
      "26183/26183 [==============================] - 13s 506us/sample - loss: 0.0695 - acc: 0.4090 - val_loss: 0.0708 - val_acc: 0.3946\n",
      "Epoch 9/100\n",
      "26183/26183 [==============================] - 14s 516us/sample - loss: 0.0692 - acc: 0.4148 - val_loss: 0.1042 - val_acc: 0.1465\n",
      "Epoch 10/100\n",
      "26183/26183 [==============================] - 13s 507us/sample - loss: 0.0690 - acc: 0.4181 - val_loss: 0.0687 - val_acc: 0.4368\n",
      "Epoch 11/100\n",
      "26183/26183 [==============================] - 14s 521us/sample - loss: 0.0688 - acc: 0.4189 - val_loss: 0.0698 - val_acc: 0.4033\n",
      "Epoch 12/100\n",
      "26183/26183 [==============================] - 14s 516us/sample - loss: 0.0686 - acc: 0.4211 - val_loss: 0.0704 - val_acc: 0.3920\n",
      "Epoch 13/100\n",
      "26183/26183 [==============================] - 13s 506us/sample - loss: 0.0685 - acc: 0.4199 - val_loss: 0.0754 - val_acc: 0.3564\n",
      "Epoch 14/100\n",
      "26183/26183 [==============================] - 13s 513us/sample - loss: 0.0684 - acc: 0.4252 - val_loss: 0.0994 - val_acc: 0.1677\n",
      "Epoch 15/100\n",
      "26183/26183 [==============================] - 13s 511us/sample - loss: 0.0683 - acc: 0.4216 - val_loss: 0.0847 - val_acc: 0.2440\n",
      "Epoch 16/100\n",
      "26183/26183 [==============================] - 14s 521us/sample - loss: 0.0682 - acc: 0.4242 - val_loss: 0.0888 - val_acc: 0.2400\n",
      "Epoch 17/100\n",
      "26183/26183 [==============================] - 14s 517us/sample - loss: 0.0681 - acc: 0.4214 - val_loss: 0.0699 - val_acc: 0.4027\n",
      "Epoch 18/100\n",
      "26183/26183 [==============================] - 13s 507us/sample - loss: 0.0680 - acc: 0.4271 - val_loss: 0.0795 - val_acc: 0.2903\n",
      "Epoch 19/100\n",
      "26183/26183 [==============================] - 14s 522us/sample - loss: 0.0679 - acc: 0.4284 - val_loss: 0.0687 - val_acc: 0.4262\n",
      "Epoch 20/100\n",
      "26183/26183 [==============================] - 13s 512us/sample - loss: 0.0677 - acc: 0.4281 - val_loss: 0.0699 - val_acc: 0.4086\n",
      "Epoch 21/100\n",
      "26183/26183 [==============================] - 13s 514us/sample - loss: 0.0676 - acc: 0.4329 - val_loss: 0.0689 - val_acc: 0.4149\n",
      "Epoch 22/100\n",
      "26183/26183 [==============================] - 14s 527us/sample - loss: 0.0676 - acc: 0.4312 - val_loss: 0.1049 - val_acc: 0.1514\n",
      "Epoch 23/100\n",
      "26183/26183 [==============================] - 13s 507us/sample - loss: 0.0719 - acc: 0.3777 - val_loss: 0.0724 - val_acc: 0.3727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'epochs': 100,\n",
       " 'steps': 1637,\n",
       " 'samples': 26183,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=16, epochs=100, callbacks=[early_stop], validation_data=(x_val, y_val))\n",
    "hist.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0698235612915749 - acc: 0.39520958065986633\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(problem_x)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m%d_%H%M')\n",
    "pred = pd.DataFrame(pred.reshape(365, 8), index=range(1, 366), columns=[f\"kp_{_}h\" for _ in range(0, 24, 3)])\n",
    "pred.to_csv(f\"models/gru{timestamp}(loss{round(float(loss), 3)}_acc{round(float(acc), 2)}).csv\")\n",
    "\n",
    "print(f\"loss: {loss} - acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40912 samples\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016DDF4E0BF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016DDF4E0BF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "40912/40912 - 16s - loss: 0.0735 - acc: 0.3849\n",
      "Epoch 2/25\n",
      "40912/40912 - 14s - loss: 0.0695 - acc: 0.4115\n",
      "Epoch 3/25\n",
      "40912/40912 - 14s - loss: 0.0689 - acc: 0.4183\n",
      "Epoch 4/25\n",
      "40912/40912 - 15s - loss: 0.0686 - acc: 0.4191\n",
      "Epoch 5/25\n",
      "40912/40912 - 14s - loss: 0.0683 - acc: 0.4214\n",
      "Epoch 6/25\n",
      "40912/40912 - 14s - loss: 0.0682 - acc: 0.4239\n",
      "Epoch 7/25\n",
      "40912/40912 - 14s - loss: 0.0680 - acc: 0.4264\n",
      "Epoch 8/25\n",
      "40912/40912 - 14s - loss: 0.0678 - acc: 0.4264\n",
      "Epoch 9/25\n",
      "40912/40912 - 14s - loss: 0.0676 - acc: 0.4307\n",
      "Epoch 10/25\n",
      "40912/40912 - 14s - loss: 0.0677 - acc: 0.4289\n",
      "Epoch 11/25\n",
      "40912/40912 - 15s - loss: 0.0680 - acc: 0.4257\n",
      "Epoch 12/25\n",
      "40912/40912 - 14s - loss: 0.0687 - acc: 0.4181\n",
      "Epoch 13/25\n",
      "40912/40912 - 14s - loss: 0.0678 - acc: 0.4274\n",
      "Epoch 14/25\n",
      "40912/40912 - 14s - loss: 0.0675 - acc: 0.4314\n",
      "Epoch 15/25\n",
      "40912/40912 - 14s - loss: 0.0674 - acc: 0.4323\n",
      "Epoch 16/25\n",
      "40912/40912 - 14s - loss: 0.0674 - acc: 0.4319\n",
      "Epoch 17/25\n",
      "40912/40912 - 14s - loss: 0.0672 - acc: 0.4377\n",
      "Epoch 18/25\n",
      "40912/40912 - 14s - loss: 0.0671 - acc: 0.4411\n",
      "Epoch 19/25\n",
      "40912/40912 - 14s - loss: 0.0673 - acc: 0.4378\n",
      "Epoch 20/25\n",
      "40912/40912 - 15s - loss: 0.0669 - acc: 0.4390\n",
      "Epoch 21/25\n",
      "40912/40912 - 14s - loss: 0.0671 - acc: 0.4371\n",
      "Epoch 22/25\n",
      "40912/40912 - 14s - loss: 0.0674 - acc: 0.4334\n",
      "Epoch 23/25\n",
      "40912/40912 - 14s - loss: 0.0671 - acc: 0.4347\n",
      "Epoch 24/25\n",
      "40912/40912 - 14s - loss: 0.0670 - acc: 0.4361\n",
      "Epoch 25/25\n",
      "40912/40912 - 15s - loss: 0.0669 - acc: 0.4398\n"
     ]
    }
   ],
   "source": [
    "model.fit(ace_x, ace_y, batch_size=16, epochs=25, verbose=2)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "timestamp = datetime.now().strftime('%Y-%m%d_%H%M')\n",
    "pred = model.predict_classes(problem_x)\n",
    "pred = pd.DataFrame(pred.reshape(365, 8), index=range(1, 366), columns=[f\"kp_{_}h\" for _ in range(0, 24, 3)])\n",
    "pred.to_csv(f\"models/ace_gru{timestamp}(loss{round(float(loss), 3)}_acc{round(float(acc), 2)}).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
